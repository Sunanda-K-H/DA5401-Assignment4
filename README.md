# DA5401 A4: GMM-Based Synthetic Sampling for Imbalanced Data

## Overview
This assignment demonstrates the effectiveness of **Gaussian Mixture Models (GMMs)** for generating synthetic samples in highly imbalanced datasets, specifically applied to [credit card fraud detection](https://www.kaggle.com/datasets/mlg-ulb/creditcardfraud).  

The dataset is extremely skewed, with fraudulent transactions accounting for less than 0.2% of total transactions. Standard machine learning models tend to achieve high accuracy by favoring the majority (non-fraud) class while failing to detect the minority (fraud) class.  

To address this issue, **GMM-based synthetic sampling** is explored as an alternative to simpler oversampling methods such as SMOTE.  

---

## Dataset
- Total transactions: **284,807**  
- Fraudulent transactions: **492 (0.172%)**  
- Features:  
  - **V1–V28**: anonymized PCA-transformed features  
  - **Time**: seconds elapsed since first transaction  
  - **Amount**: transaction amount  
  - **Class**: target label (1 = Fraud, 0 = Non-Fraud)  

---

## Project Structure

```
DA5401-Assignment4/
├── README.md
├── DA5401_A4_DA25M015.ipynb
└── requirements.txt
```

---

## How to Run

- Running in cloud environments (e.g., Colab/Kaggle) may cause issues with imbalanced-learn installation. Local execution is recommended.
1. Ensure proper environment setup:
```bash
python -m venv .venv
source .venv/bin/activate
```
2. Install dependencies:
   ```bash
   pip install -r requirements.txt
   ```
---

## Methodology

### 1. Exploratory Data Analysis (EDA)
- **Correlation Analysis**: Identified weak correlations between certain features (e.g., V11, V4, V2) and fraud.  
- **Outlier Detection**: Boxplots highlighted extreme values in fraud-related features. Outliers were removed to prevent GMM distortion.  
- **PCA & t-SNE Visualization**:  
  - PCA projection showed heavy overlap between fraud and non-fraud.  
  - t-SNE revealed sub-clusters of fraud, motivating the use of GMM to capture multi-modal fraud distributions.  

---

### 2. Baseline Model
- Logistic Regression trained on **imbalanced data**.  
- Results:  
  - Accuracy: **99.91%** (misleading due to imbalance)  
  - Fraud (minority) metrics: **Precision = 0.85, Recall = 0.61, F1 = 0.71**  
  - Many fraud cases missed (false negatives).  

---

### 3. GMM-Based Oversampling
- Fitted GMM on minority class only.  
- Number of Gaussian components $K$ selected using **Bayesian Information Criterion (BIC)**.  
  - AIC favored very large K (overfitting).  
  - BIC minimized at **K ≈ 3–6**, a stable choice.  
- Synthetic fraud samples generated by sampling from the fitted GMM until minority matched majority.  

---

### 4. Cluster-Based Undersampling (CBU) + GMM
- Applied **ClusterCentroids** to reduce majority class size.  
- Used GMM sampling on fraud to balance the reduced majority population.  
- Aimed to reduce extreme class imbalance while preserving majority diversity.  

---

### 5. Model Training & Evaluation
- Logistic Regression trained on three datasets:
  1. **Baseline (imbalanced)**
  2. **GMM Oversampling**
  3. **CBU + GMM Oversampling**

- Evaluation performed on the **original imbalanced test set** using:
  - Accuracy
  - Precision, Recall, F1-score
  - Confusion Matrix

---

## Results

### Baseline
- Fraud Precision: **0.85**  
- Fraud Recall: **0.61**  
- Fraud F1: **0.71**

### GMM Oversampling
- Fraud Precision: **0.10**  
- Fraud Recall: **0.85**  
- Fraud F1: **0.18**

### CBU + GMM
- Fraud Precision: **0.06**  
- Fraud Recall: **0.85**  
- Fraud F1: **0.10**

---

## Analysis
- **Improvement in Recall**:  
  - GMM oversampling increased fraud recall from 0.61 → 0.85, successfully detecting more frauds.  
- **Drop in Precision**:  
  - Precision dropped sharply, leading to many false positives (false alarms).  
- **Trade-off**:  
  - Baseline = fewer false positives, but more missed frauds.  
  - GMM = more frauds detected, but large increase in false positives.  
- **CBU + GMM**: Further reduced precision due to smaller majority population, while recall stayed high.  

---

## Conclusion & Recommendation
- **GMM oversampling is effective for improving sensitivity to fraud (higher recall).**  
- However, the trade-off is a **significant loss in precision**, which may be problematic in real-world fraud detection due to high false alarm costs.  
- Recommended approach:  
  - Use GMM oversampling if **recall is the primary objective** (e.g., catching all frauds is more critical than false alarms).  
  - Combine with **post-processing filters, anomaly detection, or ensemble models** to reduce false positives and improve precision.  
